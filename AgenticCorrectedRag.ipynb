{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c519cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\hf-gpu\\lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing modules which is used in simple RAG Project.\n",
    "#below classes we used so user can interact with LLM Models.\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint #HFE class we used to hit user query and take response from it.\n",
    "\n",
    "#below classes we used for embedding Models\n",
    "from langchain_openai import OpenAIEmbeddings  #close source model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings #open source model\n",
    "\n",
    "import pdfplumber\n",
    "\n",
    "#want to load document into workingspace using document loaders\n",
    "from langchain_community.document_loaders import PDFPlumberLoader,TextLoader\n",
    "\n",
    "#now splitting the document into chunks need splitter class\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter #this split the text document through herirachy way.\n",
    "\n",
    "#need to store the chunks embedded document to vector store we r using Pinecone.\n",
    "from pinecone import Pinecone,ServerlessSpec\n",
    "\n",
    "#integrating pinecode with langchain.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "#load the env files\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Annotated,Optional,List,Literal,TypedDict\n",
    "from dataclasses import dataclass\n",
    "from loggers import logger\n",
    "from Exception import CustomException\n",
    "import os,sys\n",
    "\n",
    "from langgraph.graph import StateGraph,START,END #using this class we can create Graph start or end of workflow\n",
    "\n",
    "#if i want to add tool support to my workflow.\n",
    "from langchain.tools import tool,Tool,StructuredTool\n",
    "\n",
    "#if i want to add toolnode in my workflow \n",
    "#(toolnode means that node have list of tool here they will decide based on user query which tool need to execute)\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "#if i need to add memory or persistence to my workflow so that it can save the state value at every checkpoint\n",
    "from langgraph.checkpoint.memory import InMemorySaver #it will save in state value to Ram memory.\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "#tools_condition will  decide if tool message is present on AI response then they redirect to toolnode or end it workflow\n",
    "from pydantic import BaseModel,Field,computed_field\n",
    "\n",
    "#this class we used to change retriever object to become tool\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "#fetching the RAG prompt from Hub.\n",
    "from langchain import hub\n",
    "\n",
    "import warnings as w\n",
    "w.filterwarnings('ignore')\n",
    "\n",
    "from langchain_core.messages import AIMessage,HumanMessage,AnyMessage,ToolMessage\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1decaedd",
   "metadata": {},
   "source": [
    "## step:1) model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a73df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groq model\n",
    "model1 = ChatGroq(\n",
    "    model=\"groq/compound-mini\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "#openai model\n",
    "model2 = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",temperature=0.1\n",
    ")\n",
    "\n",
    "#hugging face model.\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",  \n",
    "    task=\"text-generation\",  \n",
    "    \n",
    ")\n",
    "model3 = ChatHuggingFace(llm=llm)\n",
    "\n",
    "\n",
    "emb_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b6036",
   "metadata": {},
   "source": [
    "## Setting Up Pincone Database to store Embedding Vector into Index Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a959ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medical-book-index']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pinecone Basic Configuration.\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"medical-book-index\"\n",
    "\n",
    "# üîπ Ensure index exists\n",
    "existing_indexes = [idx[\"name\"] for idx in pc.list_indexes()]\n",
    "existing_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e34aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:27,446]-INFO-13-‚ÑπÔ∏è Index medical-book-index already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        tags={\"environment\": \"RAGdevelopment\"}\n",
    "    )\n",
    "    logger.info(f\"üÜï Created Pinecone index: {index_name}\")\n",
    "    import time\n",
    "    time.sleep(10)  # wait for index to be ready\n",
    "else:\n",
    "    logger.info(f\"‚ÑπÔ∏è Index {index_name} already exists. Skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a99807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x10b91e745e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(index=index, embedding=emb_model)\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d3129",
   "metadata": {},
   "source": [
    "### step:2) changing vector store to become as retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db9fe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.25} #lambda_mult will give more diversified output using MMR algorithm\n",
    ")\n",
    "base_retriever #retrievers is runnable so it means we can invoke easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff47c1",
   "metadata": {},
   "source": [
    "### step:3) Now changing vector store retriever to become tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9edb411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='medical_doc_retriever', description='Use this tool to retrieve the most relevant information from the ingested PDFs. Best suited for answering questions that require factual context or reference to the uploaded documents.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000010BB5FD5A20>, retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000010BB5FD5CF0>, retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=base_retriever,\n",
    "    name=\"medical_doc_retriever\",\n",
    "    description=(\n",
    "        \"Use this tool to retrieve the most relevant information \"\n",
    "        \"from the ingested PDFs. Best suited for answering \"\n",
    "        \"questions that require factual context or reference to \"\n",
    "        \"the uploaded documents.\"\n",
    "    )\n",
    ")\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27d9fe",
   "metadata": {},
   "source": [
    "#### #Testing the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983c4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:30,173]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Antigen‚ÄîAny substance that stimulates the body to sible retrovirus that causes AIDS in humans. Two\\nproduce antibody. forms of HIV are now recognized: HIV-1, which caus-\\nes most cases of AIDS in Europe, North and South\\nAutoimmunity‚ÄîA condition in which the body‚Äôs\\nAmerica, and most parts of Africa; and HIV-2, which\\nimmune system produces antibodies in response to\\nis chiefly found in West African patients. HIV-2, dis-\\nits own tissues or blood components instead of for-\\ncovered in 1986, appears to be less virulent than HIV-\\neign particles or microorganisms.\\n1 and may also have a longer latency period.\\nCCR5‚ÄîA chemokine receptor; defects in its struc-\\nImmunodeficient‚ÄîA condition in which the body‚Äôs\\nture caused by genetic mutation cause the progres-\\nimmune response is damaged, weakened, or is not\\nsion of AIDS to be prevented or slowed.\\nfunctioning properly.\\nCD4‚ÄîA type of protein molecule in human blood,\\nKaposi‚Äôs sarcoma‚ÄîA cancer of the connective tis-\\n\\nfor Disease Control and Prevention (CDC) reported that infection among heterosexuals. The chances of trans-\\n120,223 (includes only those cases in areas that have confi- mitting the disease to the child are higher in women in\\ndential HIV reporting) in the United States are HIV-posi- advanced stages of the disease. Breast feeding increases\\ntive,and 311,701 are living with AIDS (includes only those the risk of transmission by 10-20%. The use of zidovu-\\ncases where vital status is known). Of these patients,44% dine (AZT) during pregnancy,however,can decrease\\nare gay or bisexual men,20% are heterosexual intravenous the risk of transmission to the baby.\\ndrug users,and 17% are women. In addition,approximate-\\n‚Ä¢Exposure to contaminated blood or blood products.\\nly 1,000-2,000 children are born each year with HIV infec-\\nWith the introduction of blood product screening in the\\ntion. The World Health Organization (WHO) estimates that\\nmid-1980s,the incidence of HIV transmission in blood\\n\\nDIARRHEA\\nOPPORTUNISTIC INFECTIONS CAUSED BY AIDS\\nBecause the immune system cells are destroyed by the AIDS virus,many different types of infections and cancers can devel-\\nop,taking advantage of a person‚Äôs weakened immune system.(Illustration by Electronic Illustrators Group.)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the tool.\n",
    "retriever_tool.invoke({\"query\": \"Tell me about why AIDS is happened\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92cf677",
   "metadata": {},
   "source": [
    "#### Note :- adding more tools to support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ac0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculator tool\n",
    "def calculator(first_num: float, second_num: float, operation: str) -> dict:\n",
    "    try:\n",
    "        if operation == \"add\": result = first_num + second_num\n",
    "        elif operation == \"sub\": result = first_num - second_num\n",
    "        elif operation == \"mul\": result = first_num * second_num\n",
    "        elif operation == \"div\": result = first_num / second_num if second_num != 0 else \"Division by zero\"\n",
    "        else: return {\"error\": f\"Unsupported operation {operation}\"}\n",
    "        return {\"first_num\": first_num, \"second_num\": second_num, \"operation\": operation, \"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "calc_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=calculator,\n",
    "    description=\"Perform basic arithmetic: add, sub, mul, div\"\n",
    ")\n",
    "\n",
    "# Stock price tool\n",
    "import requests\n",
    "def get_stock_price(symbol: str) -> dict:\n",
    "    url = f'https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={symbol}&apikey=1PPNPDOMK62HNKRO'\n",
    "    return requests.get(url).json()\n",
    "\n",
    "stock_tool = Tool(\n",
    "    name=\"StockPrice\",\n",
    "    func=get_stock_price,\n",
    "    description=\"Fetch latest stock price for a given symbol\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b00ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='medical_doc_retriever', description='Use this tool to retrieve the most relevant information from the ingested PDFs. Best suited for answering questions that require factual context or reference to the uploaded documents.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000010BB5FD5A20>, retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000010BB5FD5CF0>, retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " Tool(name='StockPrice', description='Fetch latest stock price for a given symbol', func=<function get_stock_price at 0x0000010BB54C4CA0>),\n",
       " Tool(name='Calculator', description='Perform basic arithmetic: add, sub, mul, div', func=<function calculator at 0x0000010BB54C4D30>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now combining all tolls together\n",
    "lst_tools = [retriever_tool,stock_tool,calc_tool]\n",
    "lst_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107c7aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000010BB623E7D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000010BB623DF60>, root_client=<openai.OpenAI object at 0x0000010BB623E290>, root_async_client=<openai.AsyncOpenAI object at 0x0000010BB7617310>, temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'medical_doc_retriever', 'description': 'Use this tool to retrieve the most relevant information from the ingested PDFs. Best suited for answering questions that require factual context or reference to the uploaded documents.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'StockPrice', 'description': 'Fetch latest stock price for a given symbol', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Calculator', 'description': 'Perform basic arithmetic: add, sub, mul, div', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now binding the tool with LLM Model.\n",
    "llm_with_tool  = model2.bind_tools(tools=lst_tools)\n",
    "llm_with_tool  #tools is also runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96a806",
   "metadata": {},
   "source": [
    "#### #testing tool bind with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3050f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:34,086]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_oSs6EGCsWXENc36pfzxpDP6t', 'function': {'arguments': '{\"query\":\"acne\"}', 'name': 'medical_doc_retriever'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 156, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CIgcrE9YVQTpVBPrrndCJlXcWOUWb', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--55dd23ba-26f2-41cd-a16f-19be0815e29b-0', tool_calls=[{'name': 'medical_doc_retriever', 'args': {'query': 'acne'}, 'id': 'call_oSs6EGCsWXENc36pfzxpDP6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 156, 'output_tokens': 19, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it will parallely call all the tools together based on user query give suggestions which tool is suitable or not\n",
    "initial_testing_msg = [HumanMessage(content=\"tell me about acne?\",name=\"Human\")]\n",
    "llm_with_tool.invoke(input=initial_testing_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb02987",
   "metadata": {},
   "source": [
    "## step:4) Defining State or Memory Schema that hold value throughout Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c646a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import MessagesState #this message state is prebuilt class that store mesaage in lst \n",
    "from langgraph.graph.message import add_messages,BaseMessage\n",
    "\n",
    "class StateSchema(TypedDict):\n",
    "    #key schema defining i will store all the messages init as well as Query.\n",
    "    messages : Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977485d",
   "metadata": {},
   "source": [
    "### step:5) Defineing the graph object and adding nodes and edges to graph so finally it ready the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebfc848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bb7f4ea40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating an object of stategraph class\n",
    "graph = StateGraph(state_schema=StateSchema)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f3130d",
   "metadata": {},
   "source": [
    "#### adding nodes and edges to my graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a2d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating user_query_or_respond function that perform action in node.\n",
    "def user_query_or_respond(state:StateSchema) ->StateSchema:\n",
    "    \"\"\"Call the toool binded model to generate a response based on the current state(user query). Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    #fetching the user query from state class.\n",
    "    human_msg = state['messages'] #taking user input\n",
    "    \n",
    "    #now sending this user query that is LLM who is bind with tools.\n",
    "    #it will parallely call all the tools together based on user query give suggestions which tool is suitable.\n",
    "    ai_response = llm_with_tool.invoke(input=human_msg)\n",
    "    \n",
    "    #now updating the partial state message.\n",
    "    return {\n",
    "        'messages' : [ai_response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128f235",
   "metadata": {},
   "source": [
    "### doing testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1322bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:35,269]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_d6ORs39l0PUtDLgKdQmPMKVg', 'function': {'arguments': '{\"query\":\"acne\"}', 'name': 'medical_doc_retriever'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 156, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CIgctMypZTIT7RnhQjztN42DvojGD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bd368948-61ae-43d6-b721-6221e551590f-0', tool_calls=[{'name': 'medical_doc_retriever', 'args': {'query': 'acne'}, 'id': 'call_d6ORs39l0PUtDLgKdQmPMKVg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 156, 'output_tokens': 19, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_schema = StateSchema(messages=[HumanMessage(content=\"tell me about acne?\",name=\"Human\")])\n",
    "lst_msg = user_query_or_respond(initial_schema)\n",
    "lst_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270ef66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:36,447]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  medical_doc_retriever (call_06LGqr7SB3wJiurZgT5gBHMw)\n",
      " Call ID: call_06LGqr7SB3wJiurZgT5gBHMw\n",
      "  Args:\n",
      "    query: acne\n"
     ]
    }
   ],
   "source": [
    "initial_schema = StateSchema(messages=[HumanMessage(content=\"tell me about acne?\",name=\"Human\")])\n",
    "lst_msg = user_query_or_respond(initial_schema)\n",
    "for msg in lst_msg[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4affc",
   "metadata": {},
   "source": [
    "#### Tool nodes will have all tool support init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe37bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tools(tags=None, recurse=True, explode_args=False, func_accepts={'config': ('N/A', <class 'inspect._empty'>), 'store': ('store', None)}, tools_by_name={'medical_doc_retriever': Tool(name='medical_doc_retriever', description='Use this tool to retrieve the most relevant information from the ingested PDFs. Best suited for answering questions that require factual context or reference to the uploaded documents.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000010BB5FD5A20>, retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000010BB5FD5CF0>, retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000010B91E745E0>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.25}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')), 'StockPrice': Tool(name='StockPrice', description='Fetch latest stock price for a given symbol', func=<function get_stock_price at 0x0000010BB54C4CA0>), 'Calculator': Tool(name='Calculator', description='Perform basic arithmetic: add, sub, mul, div', func=<function calculator at 0x0000010BB54C4D30>)}, tool_to_state_args={'medical_doc_retriever': {}, 'StockPrice': {}, 'Calculator': {}}, tool_to_store_arg={'medical_doc_retriever': None, 'StockPrice': None, 'Calculator': None}, handle_tool_errors=True, messages_key='messages')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if ai response coming from user_query_or_respond node have Toolmessage toh will redirect to toolnode.\n",
    "#so defining logical that perform action in toolnode.\n",
    "tools = ToolNode(tools=lst_tools)\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686cbf1",
   "metadata": {},
   "source": [
    "```\n",
    "## Very Important Meaning\n",
    "üëâ Grading documents ka matlab hai:\n",
    "LLM (ya ek heuristic) ka use karke har retrieved document ko evaluate karna ki:\n",
    "1)Kya yeh user query ke liye retrieve document relevant hai?\n",
    "2)Kya isme user ko answer dene ke liye sahi context hai?\n",
    "3)Agar multiple docs aaye to kaunsa sabse useful document hai?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0367b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticOutputParser(pydantic_object=<class '__main__.GradeDocumentSchema'>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define GrageDocument schema using pydantic.\n",
    "class GradeDocumentSchema(BaseModel):\n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "    \n",
    "#defining pydantic output parser the parser the response give us structure response.\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=GradeDocumentSchema)\n",
    "pydantic_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916027f",
   "metadata": {},
   "source": [
    "#### messages[0] ‚Üí The original user question.\n",
    "#### messages[1] ‚Üí based on user question the assistant's placeholder,suggest which tool useful to solve the user question\n",
    "#### messages[2] ‚Üí The tool response (the document retrieved)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cd1ef",
   "metadata": {},
   "source": [
    "# Router Function based grade document suggestion it redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95227017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining grade_documetn function that perform action\n",
    "def grade_document(state:StateSchema) ->Literal['generate_answer','rewrite_question']:\n",
    "    #fetching the user question and tool retrieve document from state class\n",
    "    question = state['messages'][0].content\n",
    "    context  = state['messages'][-1].content\n",
    "    \n",
    "    print(question)\n",
    "    print(context)\n",
    "    \n",
    "    #now making structure instruction prompt that will decide the fetch document user question is relevant or not\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a relevance grader. \n",
    "        Your task is to decide whether a retrieved document is relevant to a given user question.\n",
    "\n",
    "        Retrieved document:\n",
    "        {context}\n",
    "\n",
    "        User question:\n",
    "        {question}\n",
    "\n",
    "        Instructions:\n",
    "        - Consider both exact keyword matches and semantic meaning.\n",
    "        - If the document provides information that answers or is directly related to the question, grade it as 'yes'.\n",
    "        - If the document does not provide relevant information, grade it as 'no'.\n",
    "        Return the answer strictly in this format:\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\",\"question\"],\n",
    "        partial_variables={'format_instructions':pydantic_parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    #now passing the structure instruction to llm model.\n",
    "    chain = prompt | model2 \n",
    "    \n",
    "    #chain is runnbale so we can invoke and get ai response.\n",
    "    response = chain.invoke({\"context\":context,\"question\":question})\n",
    "    print(response.binary_score)\n",
    "    \n",
    "    score = response.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2afb1655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bb7f4ea40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(node=\"understand_user_query_or_respond\",action=user_query_or_respond)\n",
    "graph.add_node(node = \"vectorretriever\", action=tools)\n",
    "#adding edges to graph.\n",
    "graph.add_edge(START,\"understand_user_query_or_respond\")\n",
    "graph.add_conditional_edges(\n",
    "    \"understand_user_query_or_respond\"\n",
    "    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
    "    ,tools_condition,\n",
    "    {\n",
    "        \"tools\":\"vectorretriever\",\n",
    "        END:END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db74d11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:37,572]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-09-23 01:06:38,691]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='tell me about acne?', additional_kwargs={}, response_metadata={}, name='Human', id='b17a84bd-bcfb-4f8a-af65-eef5849c7bfe'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cZ6VPGEn0tamMUYmOR6bk0oG', 'function': {'arguments': '{\"query\":\"acne\"}', 'name': 'medical_doc_retriever'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 156, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CIgcvA0345WsRCP2uke9DcDy2yeS1', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b7be1602-fadf-4e80-8be4-ca0d3504cec9-0', tool_calls=[{'name': 'medical_doc_retriever', 'args': {'query': 'acne'}, 'id': 'call_cZ6VPGEn0tamMUYmOR6bk0oG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 156, 'output_tokens': 19, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='disease specialist,or an endocrinologist,a specialist who\\ntreats diseases of the body‚Äôs endocrine (hormones and\\nglands) system.\\nAcne has a characteristic appearance and is not diffi-\\ncult to diagnose. The doctor takes a complete medical\\nhistory,including questions about skin care,diet,factors\\ncausing flare-ups,medication use,and prior treatment.\\nPhysical examination includes the face, upper neck,\\nchest,shoulders,back,and other affected areas. Under\\ngood lighting,the doctor determines what types and how\\nmany blemishes are present,whether they are inflamed,\\nwhether they are deep or superficial,and whether there is\\nscarring or skin discoloration.\\nIn teenagers, acne is often found on the forehead,\\nnose,and chin. As people get older,acne tends to appear\\ntowards the outer part of the face. Adult women may\\nhave acne on their chins and around their mouths. The\\nelderly may develop whiteheads and blackheads on the\\nupper cheeks and skin around the eyes.\\n\\nusing abrasive soaps or cleansers and products that might problems in nursing babies.\\nGALE ENCYCLOPEDIA OF MEDICINE 2 227\\nAntiacne\\ndrugs\\nGEM - 0001 to 0432 - A 10/22/03 1:42 PM Page 227\\nAntiacne Drugs\\nBrand Name (Generic Name) Possible Common Side Effects Include:\\nAccutane (isotretinoin) Dry skin, dry mouth, conjunctivitis\\nBenzamycin Dry and itchy skin\\nCleocin T (clindamycin phosphate) Dry skin\\nDesquam-E (benzoyl peroxide) Itching, red and peeling skin\\nErythromycin topical (A/T/S, erycette, t-stat) Burning, dry skin, hives, red and peeling skin\\nMinocin (minocycline hydrochloride) Headache, hives, diarrhea, peeling skin, vomiting\\nRetin-A (tretinoin) Darkening of the skin, blistering, crusted, or puffy skin\\n\\ncell stickiness. It is the treatment of choice for severe acne\\nsalt. Supplementation with herbs such as burdock root\\nwith cysts and nodules,and is used with or without topical\\n(Arctium lappa), red clover (Trifolium pratense), and\\nor oral antibiotics. Taken for four to five months,it pro-\\nmilk thistle (Silybum marianum),and with nutrients such\\nvides long-term disease control in up to 60% of patients. If\\nas essential fatty acids,vitamin B complex,zinc,vitamin\\nthe acne reappears,another course of isotretinoin may be\\nA,and chromium is also recommended. Chinese herbal\\nneeded by about 20% of patients,while another 20% may\\nremedies used for acne include cnidium seed (Cnidium\\ndo well with topical drugs or oral antibiotics. Side effects\\nmonnieri) and honeysuckle flower (Lonicera japonica).\\ninclude temporary worsening of the acne,dry skin,nose-\\nWholistic physicians or nutritionists can recommend the\\nbleeds,vision disorders,and elevated liver enzymes,blood\\nproper amounts of these herbs.', name='medical_doc_retriever', id='b4789da0-28eb-478c-836c-fea66b3e5bac', tool_call_id='call_cZ6VPGEn0tamMUYmOR6bk0oG')]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "#workflow is runnable passing initial state message to this worklfow.\n",
    "initial_schema = StateSchema(messages=[HumanMessage(content=\"tell me about acne?\",name=\"Human\")])\n",
    "workflow.invoke(input=initial_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b980b0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 01:06:40,444]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-09-23 01:06:42,287]-INFO-1025-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Human\n",
      "\n",
      "tell me about acne?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  medical_doc_retriever (call_mG7YIa0UPb98T7OuytOQlI6S)\n",
      " Call ID: call_mG7YIa0UPb98T7OuytOQlI6S\n",
      "  Args:\n",
      "    query: acne\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: medical_doc_retriever\n",
      "\n",
      "disease specialist,or an endocrinologist,a specialist who\n",
      "treats diseases of the body‚Äôs endocrine (hormones and\n",
      "glands) system.\n",
      "Acne has a characteristic appearance and is not diffi-\n",
      "cult to diagnose. The doctor takes a complete medical\n",
      "history,including questions about skin care,diet,factors\n",
      "causing flare-ups,medication use,and prior treatment.\n",
      "Physical examination includes the face, upper neck,\n",
      "chest,shoulders,back,and other affected areas. Under\n",
      "good lighting,the doctor determines what types and how\n",
      "many blemishes are present,whether they are inflamed,\n",
      "whether they are deep or superficial,and whether there is\n",
      "scarring or skin discoloration.\n",
      "In teenagers, acne is often found on the forehead,\n",
      "nose,and chin. As people get older,acne tends to appear\n",
      "towards the outer part of the face. Adult women may\n",
      "have acne on their chins and around their mouths. The\n",
      "elderly may develop whiteheads and blackheads on the\n",
      "upper cheeks and skin around the eyes.\n",
      "\n",
      "using abrasive soaps or cleansers and products that might problems in nursing babies.\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2 227\n",
      "Antiacne\n",
      "drugs\n",
      "GEM - 0001 to 0432 - A 10/22/03 1:42 PM Page 227\n",
      "Antiacne Drugs\n",
      "Brand Name (Generic Name) Possible Common Side Effects Include:\n",
      "Accutane (isotretinoin) Dry skin, dry mouth, conjunctivitis\n",
      "Benzamycin Dry and itchy skin\n",
      "Cleocin T (clindamycin phosphate) Dry skin\n",
      "Desquam-E (benzoyl peroxide) Itching, red and peeling skin\n",
      "Erythromycin topical (A/T/S, erycette, t-stat) Burning, dry skin, hives, red and peeling skin\n",
      "Minocin (minocycline hydrochloride) Headache, hives, diarrhea, peeling skin, vomiting\n",
      "Retin-A (tretinoin) Darkening of the skin, blistering, crusted, or puffy skin\n",
      "\n",
      "cell stickiness. It is the treatment of choice for severe acne\n",
      "salt. Supplementation with herbs such as burdock root\n",
      "with cysts and nodules,and is used with or without topical\n",
      "(Arctium lappa), red clover (Trifolium pratense), and\n",
      "or oral antibiotics. Taken for four to five months,it pro-\n",
      "milk thistle (Silybum marianum),and with nutrients such\n",
      "vides long-term disease control in up to 60% of patients. If\n",
      "as essential fatty acids,vitamin B complex,zinc,vitamin\n",
      "the acne reappears,another course of isotretinoin may be\n",
      "A,and chromium is also recommended. Chinese herbal\n",
      "needed by about 20% of patients,while another 20% may\n",
      "remedies used for acne include cnidium seed (Cnidium\n",
      "do well with topical drugs or oral antibiotics. Side effects\n",
      "monnieri) and honeysuckle flower (Lonicera japonica).\n",
      "include temporary worsening of the acne,dry skin,nose-\n",
      "Wholistic physicians or nutritionists can recommend the\n",
      "bleeds,vision disorders,and elevated liver enzymes,blood\n",
      "proper amounts of these herbs.\n"
     ]
    }
   ],
   "source": [
    "for msg in workflow.invoke(input=initial_schema)[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d11ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
